import { GoogleGenAI } from "@google/genai";
import { PlumeResponse, ChatMessage, Tone, Length, Fidelity, User, QuestionOption, LifeLocation, Emotion } from "../types";
import { logger } from "../utils/logger";

// --- PROTOCOLE XML STRICT (PRD v2) ---
// Ce prompt force l'IA √† cloisonner ses r√©ponses pour √©viter la pollution narrative.
const BASE_SYSTEM_INSTRUCTION = `
[ROLE]
Tu es PLUME, l'Architecte de la M√©moire. Tu assistes un auteur dans la r√©daction de son autobiographie.
Ton but n'est pas de discuter pour rien, mais de TRANSFORMER ses souvenirs bruts en r√©cit litt√©raire.

[PROTOCOLE DE R√âPONSE - CRITIQUE]
Tu dois TOUJOURS r√©pondre en utilisant STRICTEMENT cette structure XML. 
N'√©cris RIEN en dehors des balises.

<THINKING>
(Analyse ici la demande de l'auteur. Identifie :
- L'intention : Est-ce une nouvelle pierre √† l'√©difice ou une simple remarque ?
- Les entit√©s : Qui, Quoi, O√π, Quand ?
- L'√©motion dominante.
- La strat√©gie : Dois-je poser une question ou √©crire ?)
</THINKING>

<CONVERSATION>
(Ici, adresse-toi directement √† l'auteur.
- Sois bienveillant, curieux et encourageant.
- Si le souvenir est flou, pose UNE question pr√©cise pour d√©bloquer un d√©tail sensoriel.
- Ne r√©p√®te JAMAIS ce que tu as √©crit dans <NARRATIVE>.
- RESTE DANS LE R√îLE D'ASSISTANT. Ne "joue" pas le souvenir.)
</CONVERSATION>

<NARRATIVE>
(Ici, √©cris le PROCHAIN PARAGRAPHE du livre.
- Utilise la PREMI√àRE PERSONNE ("Je").
- Adopte le style demand√© (Ton/Longueur).
- TISSE le nouveau souvenir avec les pr√©c√©dents si pertinent.
- Si l'utilisateur ne donne pas de mati√®re substantielle, laisse cette balise VIDE.
- NE R√âSUME PAS ce qui a d√©j√† √©t√© √©crit. AVANCE.)
</NARRATIVE>

<METADATA>
(JSON strict pour alimenter la base de donn√©es.
{
  "dates_chronologie": ["1995", "√ât√© 2002"],
  "lieux_cites": ["Chamb√©ry", "Plage de Nice"],
  "personnages_cites": ["Grand-m√®re"],
  "tags_suggeres": ["Enfance", "Vacances"],
  "emotion": "Nostalgie"
}
Si rien de nouveau, renvoie des tableaux vides.)
</METADATA>

[R√àGLES DE STYLE]
- Ton : Adapte-toi au param√®tre fourni (ex: Authentique = oral, simple).
- Fais sentir, ne dis pas (Show, don't tell).

[RELANCE MA√èEUTIQUE]
Pour finir, propose 3 angles de relance dans cette balise sp√©ciale :
<QUESTIONS>
EMOTION|Question sur le ressenti ?
ACTION|Question sur les faits ?
SENSORIEL|Question sur les sens (odeur, lumi√®re) ?
</QUESTIONS>
`;

const parsePlumeResponse = (text: string): PlumeResponse => {
  // 1. Robust Regex Extraction
  // We allow optional spaces inside tags: < CONVERSATION >
  const tagRegex = (tagName: string) => new RegExp(`<\\s*${tagName}\\s*>([\\s\\S]*?)(?:<\\/\\s*${tagName}\\s*>|$)`, 'i');

  // Note: The non-greedy capture ([\s\S]*?) combined with (?:ClosingTag|$) allows capturing 
  // content even if the closing tag is missing (truncated response), stopping at end of string.
  // Ideally we prefer matching the closing tag, so we might try strict match first.

  const extract = (tagName: string): string => {
    // Try strict match first (with closing tag)
    const strictRegex = new RegExp(`<\\s*${tagName}\\s*>([\\s\\S]*?)<\\/\\s*${tagName}\\s*>`, 'i');
    const strictMatch = text.match(strictRegex);
    if (strictMatch) return strictMatch[1].trim();

    // Fallback: Match from open tag to end of string (or next start of similar tag? No, assume hierarchy is simple)
    // Actually, let's keep it simple: If strict fails, we might miss data. 
    // But for "Kickstarter", it's better to get partial text than nothing.
    // Let's rely on standard regex but maybe flexible on the closing side if we suspect truncation.
    return '';
  };

  // We revert to standard robust regexes but with space tolerance
  // We use [\s\S]*? to be non-greedy.
  const thinking = text.match(/<\s*THINKING\s*>([\s\S]*?)<\/\s*THINKING\s*>/i)?.[1]?.trim() || '';
  const narrative = text.match(/<\s*NARRATIVE\s*>([\s\S]*?)<\/\s*NARRATIVE\s*>/i)?.[1]?.trim() || '';
  const conversation = text.match(/<\s*CONVERSATION\s*>([\s\S]*?)<\/\s*CONVERSATION\s*>/i)?.[1]?.trim() || '';
  const metadataStr = text.match(/<\s*METADATA\s*>([\s\S]*?)<\/\s*METADATA\s*>/i)?.[1]?.trim() || '{}';
  const questionsStr = text.match(/<\s*QUESTIONS\s*>([\s\S]*?)<\/\s*QUESTIONS\s*>/i)?.[1]?.trim() || '';

  // 2. Parsing Metadata
  let parsedData = {
    dates_chronologie: [],
    lieux_cites: [],
    personnages_cites: [],
    tags_suggeres: [],
    emotion: 'Neutre'
  };

  try {
    let cleanJson = metadataStr.replace(/```json/g, '').replace(/```/g, '').trim();
    const firstBrace = cleanJson.indexOf('{');
    const lastBrace = cleanJson.lastIndexOf('}');
    if (firstBrace !== -1 && lastBrace !== -1 && lastBrace > firstBrace) {
      cleanJson = cleanJson.substring(firstBrace, lastBrace + 1);
      if (cleanJson && cleanJson !== '{}') {
        const rawMeta = JSON.parse(cleanJson);
        parsedData = {
          dates_chronologie: Array.isArray(rawMeta.dates_chronologie) ? rawMeta.dates_chronologie : [],
          lieux_cites: Array.isArray(rawMeta.lieux_cites) ? rawMeta.lieux_cites : [],
          personnages_cites: Array.isArray(rawMeta.personnages_cites) ? rawMeta.personnages_cites : [],
          tags_suggeres: Array.isArray(rawMeta.tags_suggeres) ? rawMeta.tags_suggeres : [],
          emotion: rawMeta.emotion || 'Neutre'
        };
      }
    }
  } catch (e) {
    logger.warn("JSON Metadata parsing failed", e);
  }

  // 3. Parsing Questions
  let parsedQuestions: QuestionOption[] = [];
  if (questionsStr) {
    const lines = questionsStr.split('\n');
    lines.forEach(line => {
      if (line.includes('|')) {
        const [typeRaw, text] = line.split('|');
        const type = typeRaw.trim().toLowerCase();
        let label = 'Question';
        if (type.includes('emotion')) label = '‚ù§Ô∏è √âmotion';
        else if (type.includes('action')) label = '‚ö° Action';
        else if (type.includes('sensoriel')) label = 'üëÅÔ∏è Sensoriel';

        if (text && text.trim()) {
          parsedQuestions.push({
            type: type as any,
            label,
            text: text.trim()
          });
        }
      }
    });
  }

  // PREVENT GARBAGE FALLBACK:
  // If we detected ANY of our standard tags in the text, we assume it's attempting to be XML.
  // In that case, we DO NOT fall back to returning the whole string as conversation.
  // This prevents the "Internal Monologue" from leaking into the UI if parsing fails.
  const hasXmlTags = /<\s*(THINKING|CONVERSATION|NARRATIVE|METADATA|QUESTIONS)\s*>/i.test(text);

  let finalConversation = conversation;
  // Only use raw text as fallback if NO XML tags were found AND text is not empty.
  if (!finalConversation && !narrative && !thinking && !hasXmlTags && text.trim().length > 0) {
    finalConversation = text.trim();
  }

  if (parsedQuestions.length === 0) {
    parsedQuestions.push({
      type: 'action',
      label: 'La Suite',
      text: "Que souhaitez-vous raconter ensuite ?"
    });
  }

  return {
    narrative: narrative,
    conversation: finalConversation,
    data: parsedData as any,
    suggestion: null,
    questions: parsedQuestions,
    isDrafted: false,
    thinking: thinking
  };
};

export const sendMessageToPlume = async (
  message: string,
  tone: Tone,
  length: Length,
  fidelity: Fidelity,
  history: { role: 'user' | 'model', parts: [{ text: string }] }[],
  lastValidNarrative: string = '',
  userProfile?: User | null
): Promise<PlumeResponse> => {
  if (!process.env.GEMINI_API_KEY) {
    throw new Error("API Key is missing from environment variables.");
  }

  const ai = new GoogleGenAI({ apiKey: process.env.GEMINI_API_KEY });

  let contextBlock = '';
  if (lastValidNarrative && lastValidNarrative.trim().length > 0) {
    contextBlock = `
    [CONTEXTE: DERNIER PARAGRAPHE √âCRIT]
    "${lastValidNarrative}"
    (Ce texte est d√©j√† valid√©. Encha√Æne sur la suite ou traite la nouvelle demande.)
    `;
  }

  let bioContext = "";
  if (userProfile) {
    bioContext = `\n[PROFIL AUTEUR]\nPr√©nom: ${userProfile.firstName || 'Auteur'}\nAnn√©e naissance: ${userProfile.birthDate ? new Date(userProfile.birthDate).getFullYear() : 'Inconnue'}\n`;
  }

  const finalSystemInstruction = BASE_SYSTEM_INSTRUCTION + bioContext;

  const formattedPrompt = `
  ${contextBlock}

  [PARAM√àTRES]
  Ton: ${tone}
  Longueur: ${length}
  Fid√©lit√©: ${fidelity}
  
  [ENTR√âE AUTEUR]
  "${message}"
  `;

  try {
    const chat = ai.chats.create({
      model: 'gemini-2.5-flash',
      history: history,
      config: {
        systemInstruction: finalSystemInstruction,
      }
    });

    const result = await chat.sendMessage({ message: formattedPrompt });
    const responseText = result.text;

    if (!responseText) throw new Error("Empty response from Gemini");

    return parsePlumeResponse(responseText);

  } catch (error) {
    logger.error("Gemini API Error:", error);
    throw error;
  }
};

export const synthesizeNarrative = async (
  historySegment: { role: string, content: string }[],
  tone: Tone,
  length: Length,
  fidelity: Fidelity
): Promise<PlumeResponse> => {
  const ai = new GoogleGenAI({ apiKey: process.env.GEMINI_API_KEY! });

  const synthesisPrompt = `
    T√ÇCHE: R√©√©criture litt√©raire.
    Transforme ces notes en un paragraphe de livre autobiographique.
    Style: ${tone}. 
    Utilise "Je".

    ${fidelity === Fidelity.HAUTE ? `
    [MODE VERBATIM]
    CONSERVE EXACTEMENT LES PROPOS DE L'AUTEUR.
    Ne modifie que la ponctuation si n√©cessaire pour la fluidit√©.
    Ne change PAS le style ni le vocabulaire.
    ` : ''}
    
    NOTES:
    ${historySegment.map(m => m.content).join('\n')}
    
    FORMAT SORTIE XML:
    <NARRATIVE>Le texte ici...</NARRATIVE>
    `;

  try {
    const result = await ai.models.generateContent({
      model: 'gemini-2.5-flash',
      contents: [{ parts: [{ text: synthesisPrompt }] }]
    });

    const text = result.text || '';
    const narrative = text.match(/<NARRATIVE>([\s\S]*?)<\/NARRATIVE>/i)?.[1]?.trim() || text;

    return {
      narrative,
      data: null,
      suggestion: null,
      questions: [],
      isSynthesized: true,
      isSynthesisResult: true
    } as PlumeResponse;
  } catch (error) {
    logger.error("Synthesis failed", error);
    throw error;
  }
};

export const generateKickstarter = async (
  userProfile: User | null,
  ideas: Array<{ id: string; title: string; content: string; tags: string[] }>,
  darkZones: Array<{ title: string; description: string; category: string }>
): Promise<PlumeResponse> => {
  const ai = new GoogleGenAI({ apiKey: process.env.GEMINI_API_KEY! });
  let bioContext = "";
  if (userProfile) {
    bioContext = `\nPr√©nom: ${userProfile.firstName || 'Auteur'}\n`;
  }

  const kickstarterPrompt = `
  [T√ÇCHE]
  Accueille l'auteur pour une nouvelle session d'√©criture.
  
  [CONTEXTE]
  ${bioContext}
  Id√©es en attente: ${ideas.slice(0, 3).map(i => i.title).join(', ')}
  
  [FORMAT XML OBLIGATOIRE]
  <CONVERSATION>
  Message d'accueil chaleureux et court (2 phrases). Propose d'explorer une id√©e du coffre si pertinent.
  </CONVERSATION>
  
  <QUESTIONS>
  EMOTION|Question inspirante sur l'humeur du jour ?
  ACTION|Question sur un √©v√©nement r√©cent ?
  SENSORIEL|Question sur une image ou une odeur ?
  </QUESTIONS>
  `;

  try {
    const result = await ai.models.generateContent({
      model: 'gemini-2.5-flash',
      contents: [{ parts: [{ text: kickstarterPrompt }] }]
    });

    const text = result.text || '';
    return parsePlumeResponse(text);
  } catch (e) {
    return {
      narrative: '',
      data: null,
      suggestion: null,
      questions: [{ type: 'action', label: 'D√©part', text: 'Par quoi commen√ßons-nous ?' }]
    } as PlumeResponse;
  }
};

export const generateSouvenirTitle = async (
  narrative: string,
  metadata: any
): Promise<string> => {
  const ai = new GoogleGenAI({ apiKey: process.env.GEMINI_API_KEY! });
  const prompt = `G√©n√®re un titre court (max 6 mots) pour ce texte : "${narrative.substring(0, 300)}..."`;
  const result = await ai.models.generateContent({ model: 'gemini-1.5-flash', contents: [{ parts: [{ text: prompt }] }] });
  return result.text?.replace(/["']/g, '').trim().substring(0, 50) || 'Nouveau Souvenir';
};

export const generateTitleAndMetadata = async (text: string) => {
  return { title: "Souvenir", dates: [], characters: [], tags: [] };
};

export const buildLocationContext = (userProfile: User | null) => '';